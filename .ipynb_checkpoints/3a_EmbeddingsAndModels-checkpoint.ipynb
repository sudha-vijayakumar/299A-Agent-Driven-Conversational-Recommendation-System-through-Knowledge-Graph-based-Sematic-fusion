{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "from gensim.models import Word2Vec \n",
    "from gensim.parsing.preprocessing import preprocess_documents\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './RASA/data/'\n",
    "model_root='./RASA/offline_models/'\n",
    "processed = './Data/processing/Processed_Airbnb/'\n",
    "raw = './Data/raw/'\n",
    "\n",
    "def create_embeddings(text_corpus_listing, name):\n",
    "    processed_text_corpus = preprocess_documents(text_corpus_listing)\n",
    "    tagged_text_corpus = [TaggedDocument(d, [i]) for i, d in enumerate(processed_text_corpus)]\n",
    "    text_corpus_model = Doc2Vec(tagged_text_corpus, dm=0, vector_size=200, window=2, min_count=1, epochs=100, hs=1)\n",
    "\n",
    "    text_corpus_model.save(root+'embeddings/'+ name +'_embeddings')\n",
    "\n",
    "    return text_corpus_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "listings = pd.read_csv(raw+'listings.csv.gz', sep=',')\n",
    "reviews = pd.read_csv(processed+'ratings_filter.csv', sep=',')\n",
    "listings=listings.rename(columns={\"id\": \"listing_id\"})\n",
    "listings.to_csv(processed+'listings.csv.gz', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Review Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of.reviews:264360\n",
      "No.of.users:257032\n"
     ]
    }
   ],
   "source": [
    "reviews = reviews.dropna()\n",
    "print(\"No.of.reviews:\"+str(len(reviews)))\n",
    "users = reviews[\"reviewer_id\"].unique().tolist()\n",
    "print(\"No.of.users:\"+str(len(users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 264360 entries, 0 to 272484\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Unnamed: 0     264360 non-null  object \n",
      " 1   listing_id     264360 non-null  float64\n",
      " 2   id             264360 non-null  float64\n",
      " 3   date           264360 non-null  object \n",
      " 4   reviewer_id    264360 non-null  float64\n",
      " 5   reviewer_name  264360 non-null  object \n",
      " 6   comments       264360 non-null  object \n",
      " 7   rating         264360 non-null  float64\n",
      "dtypes: float64(4), object(4)\n",
      "memory usage: 18.2+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_corpus_model = create_embeddings(reviews['comments'].values,'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-107-d011b8cf41a5>:3: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  sims = comment_corpus_model.docvecs.most_similar(positive = [test_doc_vector])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6630650162696838 | 23626417.0\n",
      "0.6610732674598694 | 31945057.0\n",
      "0.6557047963142395 | 35632344.0\n",
      "0.6534749269485474 | 37927536.0\n",
      "0.6384268403053284 | 35855352.0\n"
     ]
    }
   ],
   "source": [
    "new_doc = gensim.parsing.preprocessing.preprocess_string(\"private room dishwasher\")\n",
    "test_doc_vector = comment_corpus_model.infer_vector(new_doc)\n",
    "sims = comment_corpus_model.docvecs.most_similar(positive = [test_doc_vector])\n",
    "topK = 5\n",
    "for s in sims[:topK]:\n",
    "    print(f\"{(s[1])} | {reviews['listing_id'].iloc[s[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of.listings:5402\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5402 entries, 0 to 5401\n",
      "Data columns (total 74 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            5402 non-null   int64  \n",
      " 1   listing_url                                   5402 non-null   object \n",
      " 2   scrape_id                                     5402 non-null   int64  \n",
      " 3   last_scraped                                  5402 non-null   object \n",
      " 4   name                                          5402 non-null   object \n",
      " 5   description                                   5392 non-null   object \n",
      " 6   neighborhood_overview                         3908 non-null   object \n",
      " 7   picture_url                                   5402 non-null   object \n",
      " 8   host_id                                       5402 non-null   int64  \n",
      " 9   host_url                                      5402 non-null   object \n",
      " 10  host_name                                     5401 non-null   object \n",
      " 11  host_since                                    5401 non-null   object \n",
      " 12  host_location                                 5389 non-null   object \n",
      " 13  host_about                                    3457 non-null   object \n",
      " 14  host_response_time                            3642 non-null   object \n",
      " 15  host_response_rate                            3642 non-null   object \n",
      " 16  host_acceptance_rate                          3897 non-null   object \n",
      " 17  host_is_superhost                             5401 non-null   object \n",
      " 18  host_thumbnail_url                            5401 non-null   object \n",
      " 19  host_picture_url                              5401 non-null   object \n",
      " 20  host_neighbourhood                            3169 non-null   object \n",
      " 21  host_listings_count                           5401 non-null   float64\n",
      " 22  host_total_listings_count                     5401 non-null   float64\n",
      " 23  host_verifications                            5402 non-null   object \n",
      " 24  host_has_profile_pic                          5401 non-null   object \n",
      " 25  host_identity_verified                        5401 non-null   object \n",
      " 26  neighbourhood                                 3908 non-null   object \n",
      " 27  neighbourhood_cleansed                        5402 non-null   object \n",
      " 28  neighbourhood_group_cleansed                  0 non-null      float64\n",
      " 29  latitude                                      5402 non-null   float64\n",
      " 30  longitude                                     5402 non-null   float64\n",
      " 31  property_type                                 5402 non-null   object \n",
      " 32  room_type                                     5402 non-null   object \n",
      " 33  accommodates                                  5402 non-null   int64  \n",
      " 34  bathrooms                                     0 non-null      float64\n",
      " 35  bathrooms_text                                5388 non-null   object \n",
      " 36  bedrooms                                      5081 non-null   float64\n",
      " 37  beds                                          5163 non-null   float64\n",
      " 38  amenities                                     5402 non-null   object \n",
      " 39  price                                         5402 non-null   object \n",
      " 40  minimum_nights                                5402 non-null   int64  \n",
      " 41  maximum_nights                                5402 non-null   int64  \n",
      " 42  minimum_minimum_nights                        5401 non-null   float64\n",
      " 43  maximum_minimum_nights                        5401 non-null   float64\n",
      " 44  minimum_maximum_nights                        5401 non-null   float64\n",
      " 45  maximum_maximum_nights                        5401 non-null   float64\n",
      " 46  minimum_nights_avg_ntm                        5401 non-null   float64\n",
      " 47  maximum_nights_avg_ntm                        5401 non-null   float64\n",
      " 48  calendar_updated                              0 non-null      float64\n",
      " 49  has_availability                              5402 non-null   object \n",
      " 50  availability_30                               5402 non-null   int64  \n",
      " 51  availability_60                               5402 non-null   int64  \n",
      " 52  availability_90                               5402 non-null   int64  \n",
      " 53  availability_365                              5402 non-null   int64  \n",
      " 54  calendar_last_scraped                         5402 non-null   object \n",
      " 55  number_of_reviews                             5402 non-null   int64  \n",
      " 56  number_of_reviews_ltm                         5402 non-null   int64  \n",
      " 57  number_of_reviews_l30d                        5402 non-null   int64  \n",
      " 58  first_review                                  4934 non-null   object \n",
      " 59  last_review                                   4934 non-null   object \n",
      " 60  review_scores_rating                          4934 non-null   float64\n",
      " 61  review_scores_accuracy                        4923 non-null   float64\n",
      " 62  review_scores_cleanliness                     4923 non-null   float64\n",
      " 63  review_scores_checkin                         4923 non-null   float64\n",
      " 64  review_scores_communication                   4923 non-null   float64\n",
      " 65  review_scores_location                        4923 non-null   float64\n",
      " 66  review_scores_value                           4923 non-null   float64\n",
      " 67  license                                       5366 non-null   object \n",
      " 68  instant_bookable                              5402 non-null   object \n",
      " 69  calculated_host_listings_count                5402 non-null   int64  \n",
      " 70  calculated_host_listings_count_entire_homes   5402 non-null   int64  \n",
      " 71  calculated_host_listings_count_private_rooms  5402 non-null   int64  \n",
      " 72  calculated_host_listings_count_shared_rooms   5402 non-null   int64  \n",
      " 73  reviews_per_month                             4934 non-null   float64\n",
      "dtypes: float64(23), int64(17), object(34)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "listings = pd.read_csv(raw+'listings.csv.gz', sep=',')\n",
    "print(\"No.of.listings:\"+str(len(listings)))\n",
    "listings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose columns to generate embeddings.\n",
    "listings = listings[['id','listing_url','name','description','neighborhood_overview','picture_url', \n",
    "'property_type','room_type','accommodates','bathrooms','bathrooms_text',                               \n",
    "'bedrooms','beds','amenities','price','minimum_nights','maximum_nights','review_scores_rating',                         \n",
    "'review_scores_accuracy','review_scores_cleanliness','review_scores_checkin',\n",
    "'review_scores_communication','review_scores_location']]\n",
    "\n",
    "listings.fillna('0', inplace=True)\n",
    "\n",
    "listings.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punc(sample_str):\n",
    "    # Create translation table in which special charcters\n",
    "    # are mapped to empty string\n",
    "    translation_table = str.maketrans('', '', string.punctuation)\n",
    "    # Remove special characters from the string using translation table\n",
    "    sample_str = sample_str.translate(translation_table)\n",
    "    return sample_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-8769852d1023>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  listings['review_scores_rating'][ind] = (float(listings['review_scores_rating'][ind]) + float(listings['review_scores_accuracy'][ind]) + float(listings['review_scores_cleanliness'][ind]) + float(listings['review_scores_checkin'][ind]) + float(listings['review_scores_communication'][ind]) + float(listings['review_scores_location'][ind]))\n",
      "<ipython-input-12-8769852d1023>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  listings['review_scores_rating'][ind] = (listings['review_scores_rating'][ind])/6\n",
      "<ipython-input-12-8769852d1023>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  listings['words_features'][ind] = 'amenities:'+listings['words_features'][ind] +'description:'+  listings['description'][ind] +'neighborhood_overview:'+  listings['neighborhood_overview'][ind]+'property_type:'+  listings['property_type'][ind]+'room_type:'+  listings['room_type'][ind]+'accommodates:'+  str(listings['accommodates'][ind])+'bedrooms:'+  str(listings['bedrooms'][ind])+'beds:'+  str(listings['beds'][ind])+'price range:'+  listings['price'][ind]\n"
     ]
    }
   ],
   "source": [
    "listings['words_features'] = listings['amenities'].apply(remove_punc)\n",
    "\n",
    "for ind in listings.index:\n",
    "     listings['review_scores_rating'][ind] = (float(listings['review_scores_rating'][ind]) + float(listings['review_scores_accuracy'][ind]) + float(listings['review_scores_cleanliness'][ind]) + float(listings['review_scores_checkin'][ind]) + float(listings['review_scores_communication'][ind]) + float(listings['review_scores_location'][ind]))\n",
    "     listings['review_scores_rating'][ind] = (listings['review_scores_rating'][ind])/6\n",
    "     listings['words_features'][ind] = 'amenities:'+listings['words_features'][ind] +'description:'+  listings['description'][ind] +'neighborhood_overview:'+  listings['neighborhood_overview'][ind]+'property_type:'+  listings['property_type'][ind]+'room_type:'+  listings['room_type'][ind]+'accommodates:'+  str(listings['accommodates'][ind])+'bedrooms:'+  str(listings['bedrooms'][ind])+'beds:'+  str(listings['beds'][ind])+'price range:'+  listings['price'][ind]\n",
    "listings = listings.rename(columns={\"review_scores_rating\": \"overall_rating\"})\n",
    "listings[\"overall_rating\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4589652717113495 | https://www.airbnb.com/rooms/25991654\n",
      "0.4400947391986847 | https://www.airbnb.com/rooms/40247038\n",
      "0.4249565899372101 | https://www.airbnb.com/rooms/8641456\n",
      "0.4234083890914917 | https://www.airbnb.com/rooms/51961840\n",
      "0.41909921169281006 | https://www.airbnb.com/rooms/49927889\n",
      "0.4160788655281067 | https://www.airbnb.com/rooms/16685383\n",
      "0.41239070892333984 | https://www.airbnb.com/rooms/32729549\n",
      "0.4093344509601593 | https://www.airbnb.com/rooms/39642322\n",
      "0.4028607904911041 | https://www.airbnb.com/rooms/28220320\n",
      "0.40280336141586304 | https://www.airbnb.com/rooms/21593642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-75f26069de46>:5: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  sims = text_corpus_model.docvecs.most_similar(positive = [test_doc_vector])\n"
     ]
    }
   ],
   "source": [
    "text_corpus_model = create_embeddings(listings['words_features'].values,'list')\n",
    "\n",
    "new_doc = gensim.parsing.preprocessing.preprocess_string(\"private room dishwasher\")\n",
    "test_doc_vector = text_corpus_model.infer_vector(new_doc)\n",
    "sims = text_corpus_model.docvecs.most_similar(positive = [test_doc_vector])\n",
    "for s in sims:\n",
    "    print(f\"{(s[1])} | {listings['listing_url'].iloc[s[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering\n",
    "- https://github.com/SarangDeshmukh7/Recommendation-Engine/blob/master/Content_Based_Filtering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = reviews[\"reviewer_id\"].unique().tolist()\n",
    "random.shuffle(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_listing = pd.merge(listings,reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews_listing['listing_id']= reviews_listing['listing_id'].astype(str)\n",
    "\n",
    "# extract 90% of user ID's\n",
    "users_train = [users[i] for i in range(round(0.9*len(users)))]\n",
    "#split data into train and validation set\n",
    "train_df = reviews_listing[reviews_listing['reviewer_id'].isin(users_train)]\n",
    "validation_df = reviews_listing[~reviews_listing['reviewer_id'].isin(users_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 233485/233485 [03:16<00:00, 1189.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#list to capture watch history of the users\n",
    "watch_train = []\n",
    "\n",
    "# populate the list with the movie ID\n",
    "for i in tqdm(users_train):\n",
    "    temp = train_df[train_df[\"reviewer_id\"] == i][\"listing_id\"].tolist()\n",
    "    watch_train.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2375641, 2401840)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train word2vec model\n",
    "model = Word2Vec(window = 10, sg = 1, hs = 0,\n",
    "                 negative = 10, \n",
    "                 alpha=0.03, min_alpha=0.0007,\n",
    "                 seed = 14)\n",
    "\n",
    "model.build_vocab(watch_train, progress_per=200)\n",
    "\n",
    "model.train(watch_train, total_examples = model.corpus_count, \n",
    "            epochs=10, report_delay=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.train(watch_train, total_examples = model.corpus_count, \n",
    "            epochs=10, report_delay=1)\n",
    "model.save(model_root+'ContentBasedFilter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-b3d13b8f8448>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  watch.drop_duplicates(inplace=True, subset='listing_id', keep=\"last\")\n"
     ]
    }
   ],
   "source": [
    "watch = train_df[[\"listing_id\",\"listing_url\",\"name\"]]\n",
    "\n",
    "# remove duplicates\n",
    "watch.drop_duplicates(inplace=True, subset='listing_id', keep=\"last\")\n",
    "\n",
    "# create movie id and tittle dictionary\n",
    "watch_dict = watch.groupby('listing_id')['listing_id'].apply(list).to_dict()\n",
    "\n",
    "def similar_watch(v, n = 5):\n",
    "\n",
    "    # extract most similar movies for the input vector\n",
    "    ms = model.wv.similar_by_vector(v, topn= n+1)[1:]\n",
    "    # extract name and similarity score of the similar movies\n",
    "    new_ms = []\n",
    "    for j in ms:\n",
    "        pair = (watch_dict[j[0]][0], j[1])\n",
    "        new_ms.append(pair)\n",
    "        \n",
    "    return new_ms        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quiet Garden View Room & Super Fast WiFi']\n"
     ]
    }
   ],
   "source": [
    "print(watch_dict['2818'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1383369', 0.9963660836219788),\n",
       " ('505650', 0.9962319135665894),\n",
       " ('18882385', 0.9962259531021118),\n",
       " ('28170875', 0.9961230158805847),\n",
       " ('23332938', 0.9960837364196777)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_watch('2818',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Refer notebook ColaborativeFiltering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pyspark\n",
    "\n",
    "# importing all the libraries we’ll require to build the book recommender\n",
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions  import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.recommendation import ALS,ALSModel\n",
    "\n",
    "# define the configurations for this Spark program\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"airbnb\")\n",
    "conf.set(\"spark.executor.memory\", \"6G\")\n",
    "conf.set(\"spark.driver.memory\", \"2G\")\n",
    "conf.set(\"spark.executor.cores\", \"4\")\n",
    "conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "conf.set(\"spark.default.parallelism\", \"4\")\n",
    "\n",
    "# create a Spark Session instead of a Spark Context\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf = conf) \\\n",
    "  .appName(\"spark session example\") \\\n",
    "  .getOrCreate()\n",
    "\n",
    "listings_df = spark.read.option(\"delimiter\", \",\").option(\"header\", \"true\").csv('/content/drive/MyDrive/299/listings.csv')\n",
    "listings_df.show(2)\n",
    "\n",
    "listings_df.select('id').distinct().show(2)\n",
    "\n",
    "user_ratings_df = spark.read.option(\"delimiter\", \",\").option(\"header\", \"true\").csv('/content/drive/MyDrive/299/ratings_filter.csv')\n",
    "# Columns User-ID, ISBN and Book-Rating were in string format, which we convert to int\n",
    "ratings_df = user_ratings_df.withColumn(\"reviewer_id\",\n",
    "                                        user_ratings_df['reviewer_id'].\\\n",
    "                                        cast(IntegerType())).\\\n",
    "\t\t\t\t\t\t\t\t\t\twithColumn(\"listing_id\", user_ratings_df['listing_id'].\\\n",
    "           \t\t\t\t\t\t\t\tcast(IntegerType())).\\\n",
    "    \t\t\t\t\t\t\t\t\twithColumn(\"rating\",\\\n",
    "                                        user_ratings_df['rating'].\\\n",
    "                                  \t\tcast(IntegerType())).\\\n",
    "        \t\t\t\t\t\t\t\tna.drop()\n",
    "ratings_df.show(2)\n",
    "\n",
    "# define parameters\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"reviewer_id\", itemCol=\"listing_id\", ratingCol=\"rating\",coldStartStrategy=\"drop\")\n",
    "#fit the model to the ratings\n",
    "model = als.fit(ratings_df)\n",
    "\n",
    "model.save(\"/content/drive/MyDrive/299/als_model\")\n",
    "\n",
    "user_ratings_df = spark.read.option(\"delimiter\", \",\").option(\"header\", \"true\").csv('/content/drive/MyDrive/299/ratings_filter.csv')\n",
    "# Columns User-ID, ISBN and Book-Rating were in string format, which we convert to int\n",
    "ratings_df = user_ratings_df.withColumn(\"reviewer_id\",\n",
    "                                        user_ratings_df['reviewer_id'].\\\n",
    "                                        cast(IntegerType())).\\\n",
    "\t\t\t\t\t\t\t\t\t\twithColumn(\"listing_id\", user_ratings_df['listing_id'].\\\n",
    "           \t\t\t\t\t\t\t\tcast(IntegerType())).\\\n",
    "    \t\t\t\t\t\t\t\t\twithColumn(\"rating\",\\\n",
    "                                        user_ratings_df['rating'].\\\n",
    "                                  \t\tcast(IntegerType())).\\\n",
    "        \t\t\t\t\t\t\t\tna.drop()\n",
    "ratings_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help link Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Text, Dict, List\n",
    "import torch\n",
    "from bert_serving.client import BertClient\n",
    "from rasa_sdk import Action, Tracker\n",
    "from rasa_sdk.executor import CollectingDispatcher\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# sentence embedding selection\n",
    "sentence_transformer_select=True\n",
    "pretrained_model='stsb-roberta-large' # Refer: https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/nli-models.md\n",
    "score_threshold = 0.70  # This confidence scores can be adjusted based on your need!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard question size 86\n",
      "Start to calculate encoder....\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def encode_standard_question(sentence_transformer_select=True, pretrained_model='bert-base-nli-mean-tokens'):\n",
    "    \"\"\"\n",
    "    This will encode all the questions available in question database into sentence embedding. The result will be stored into numpy array for comparision purpose.\n",
    "    \"\"\"\n",
    "    if sentence_transformer_select:\n",
    "        bc = SentenceTransformer(pretrained_model)\n",
    "    else:\n",
    "        bc = BertClient(check_version=False)\n",
    "    data = json.load(open(raw+\"/faq.json\", \"rt\", encoding=\"utf-8\"))\n",
    "    standard_questions = [each['q'].replace('-',' ') for each in data]\n",
    "    print(\"Standard question size\", len(standard_questions))\n",
    "    print(\"Start to calculate encoder....\")\n",
    "    if sentence_transformer_select:\n",
    "        standard_questions_encoder = torch.tensor(bc.encode(standard_questions)).numpy()\n",
    "    else:\n",
    "        standard_questions_encoder = bc.encode(standard_questions)\n",
    "    np.save(root+\"embeddings/questions_embedding\", standard_questions_encoder)\n",
    "    standard_questions_encoder_len = np.sqrt(np.sum(standard_questions_encoder * standard_questions_encoder, axis=1))\n",
    "    np.save(root+\"embeddings/questions_embedding_len\", standard_questions_encoder_len)\n",
    "\n",
    "\n",
    "encode_standard_question(sentence_transformer_select,pretrained_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
