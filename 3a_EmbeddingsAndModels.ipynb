{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script\n",
    "- **Input:** Airbnb - listings, reviews, single location.\n",
    "- **Output:** Embedded vectors of listings, reviews for traditional recommendation and vector-based \n",
    "              airbnb listing search.\n",
    "    \n",
    "- 5.5k listings | 250k reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "from gensim.models import Word2Vec \n",
    "from gensim.parsing.preprocessing import preprocess_documents\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './RASA/data/'\n",
    "model_root='./RASA/offline_models/'\n",
    "processed = './Data/processing/Processed_Airbnb/'\n",
    "raw = './Data/raw/'\n",
    "\n",
    "def create_embeddings(text_corpus_listing, name):\n",
    "    processed_text_corpus = preprocess_documents(text_corpus_listing)\n",
    "    tagged_text_corpus = [TaggedDocument(d, [i]) for i, d in enumerate(processed_text_corpus)]\n",
    "    text_corpus_model = Doc2Vec(tagged_text_corpus, dm=0, vector_size=200, window=2, min_count=1, epochs=100, hs=1)\n",
    "\n",
    "    text_corpus_model.save(root+'embeddings/'+ name +'_embeddings')\n",
    "\n",
    "    return text_corpus_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = pd.read_csv(raw+'listings.csv.gz', sep=',')\n",
    "reviews = pd.read_csv(processed+'ratings_filter.csv', sep=',')\n",
    "listings=listings.rename(columns={\"id\": \"listing_id\"})\n",
    "listings.to_csv(processed+'listings.csv.gz', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Review Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of.reviews:247258\n",
      "No.of.users:240950\n"
     ]
    }
   ],
   "source": [
    "reviews = reviews.dropna()\n",
    "print(\"No.of.reviews:\"+str(len(reviews)))\n",
    "users = reviews[\"reviewer_id\"].unique().tolist()\n",
    "print(\"No.of.users:\"+str(len(users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 247258 entries, 0 to 254720\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   listing_id     247258 non-null  object \n",
      " 1   id             247258 non-null  float64\n",
      " 2   date           247258 non-null  object \n",
      " 3   reviewer_id    247258 non-null  float64\n",
      " 4   reviewer_name  247258 non-null  object \n",
      " 5   comments       247258 non-null  object \n",
      " 6   rating         247258 non-null  float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 15.1+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_corpus_model = create_embeddings(reviews['comments'].values,'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d011b8cf41a5>:3: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  sims = comment_corpus_model.docvecs.most_similar(positive = [test_doc_vector])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6773742437362671 | 35632344\n",
      "0.6478351950645447 | 23626417\n",
      "0.6381070017814636 | 37927536\n",
      "0.6166751980781555 | 25310429\n",
      "0.614802896976471 | 21019335\n"
     ]
    }
   ],
   "source": [
    "new_doc = gensim.parsing.preprocessing.preprocess_string(\"private room dishwasher\")\n",
    "test_doc_vector = comment_corpus_model.infer_vector(new_doc)\n",
    "sims = comment_corpus_model.docvecs.most_similar(positive = [test_doc_vector])\n",
    "topK = 5\n",
    "for s in sims[:topK]:\n",
    "    print(f\"{(s[1])} | {reviews['listing_id'].iloc[s[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of.listings:5402\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5402 entries, 0 to 5401\n",
      "Data columns (total 74 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            5402 non-null   int64  \n",
      " 1   listing_url                                   5402 non-null   object \n",
      " 2   scrape_id                                     5402 non-null   int64  \n",
      " 3   last_scraped                                  5402 non-null   object \n",
      " 4   name                                          5402 non-null   object \n",
      " 5   description                                   5392 non-null   object \n",
      " 6   neighborhood_overview                         3908 non-null   object \n",
      " 7   picture_url                                   5402 non-null   object \n",
      " 8   host_id                                       5402 non-null   int64  \n",
      " 9   host_url                                      5402 non-null   object \n",
      " 10  host_name                                     5401 non-null   object \n",
      " 11  host_since                                    5401 non-null   object \n",
      " 12  host_location                                 5389 non-null   object \n",
      " 13  host_about                                    3457 non-null   object \n",
      " 14  host_response_time                            3642 non-null   object \n",
      " 15  host_response_rate                            3642 non-null   object \n",
      " 16  host_acceptance_rate                          3897 non-null   object \n",
      " 17  host_is_superhost                             5401 non-null   object \n",
      " 18  host_thumbnail_url                            5401 non-null   object \n",
      " 19  host_picture_url                              5401 non-null   object \n",
      " 20  host_neighbourhood                            3169 non-null   object \n",
      " 21  host_listings_count                           5401 non-null   float64\n",
      " 22  host_total_listings_count                     5401 non-null   float64\n",
      " 23  host_verifications                            5402 non-null   object \n",
      " 24  host_has_profile_pic                          5401 non-null   object \n",
      " 25  host_identity_verified                        5401 non-null   object \n",
      " 26  neighbourhood                                 3908 non-null   object \n",
      " 27  neighbourhood_cleansed                        5402 non-null   object \n",
      " 28  neighbourhood_group_cleansed                  0 non-null      float64\n",
      " 29  latitude                                      5402 non-null   float64\n",
      " 30  longitude                                     5402 non-null   float64\n",
      " 31  property_type                                 5402 non-null   object \n",
      " 32  room_type                                     5402 non-null   object \n",
      " 33  accommodates                                  5402 non-null   int64  \n",
      " 34  bathrooms                                     0 non-null      float64\n",
      " 35  bathrooms_text                                5388 non-null   object \n",
      " 36  bedrooms                                      5081 non-null   float64\n",
      " 37  beds                                          5163 non-null   float64\n",
      " 38  amenities                                     5402 non-null   object \n",
      " 39  price                                         5402 non-null   object \n",
      " 40  minimum_nights                                5402 non-null   int64  \n",
      " 41  maximum_nights                                5402 non-null   int64  \n",
      " 42  minimum_minimum_nights                        5401 non-null   float64\n",
      " 43  maximum_minimum_nights                        5401 non-null   float64\n",
      " 44  minimum_maximum_nights                        5401 non-null   float64\n",
      " 45  maximum_maximum_nights                        5401 non-null   float64\n",
      " 46  minimum_nights_avg_ntm                        5401 non-null   float64\n",
      " 47  maximum_nights_avg_ntm                        5401 non-null   float64\n",
      " 48  calendar_updated                              0 non-null      float64\n",
      " 49  has_availability                              5402 non-null   object \n",
      " 50  availability_30                               5402 non-null   int64  \n",
      " 51  availability_60                               5402 non-null   int64  \n",
      " 52  availability_90                               5402 non-null   int64  \n",
      " 53  availability_365                              5402 non-null   int64  \n",
      " 54  calendar_last_scraped                         5402 non-null   object \n",
      " 55  number_of_reviews                             5402 non-null   int64  \n",
      " 56  number_of_reviews_ltm                         5402 non-null   int64  \n",
      " 57  number_of_reviews_l30d                        5402 non-null   int64  \n",
      " 58  first_review                                  4934 non-null   object \n",
      " 59  last_review                                   4934 non-null   object \n",
      " 60  review_scores_rating                          4934 non-null   float64\n",
      " 61  review_scores_accuracy                        4923 non-null   float64\n",
      " 62  review_scores_cleanliness                     4923 non-null   float64\n",
      " 63  review_scores_checkin                         4923 non-null   float64\n",
      " 64  review_scores_communication                   4923 non-null   float64\n",
      " 65  review_scores_location                        4923 non-null   float64\n",
      " 66  review_scores_value                           4923 non-null   float64\n",
      " 67  license                                       5366 non-null   object \n",
      " 68  instant_bookable                              5402 non-null   object \n",
      " 69  calculated_host_listings_count                5402 non-null   int64  \n",
      " 70  calculated_host_listings_count_entire_homes   5402 non-null   int64  \n",
      " 71  calculated_host_listings_count_private_rooms  5402 non-null   int64  \n",
      " 72  calculated_host_listings_count_shared_rooms   5402 non-null   int64  \n",
      " 73  reviews_per_month                             4934 non-null   float64\n",
      "dtypes: float64(23), int64(17), object(34)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "listings = pd.read_csv(raw+'listings.csv.gz', sep=',')\n",
    "print(\"No.of.listings:\"+str(len(listings)))\n",
    "listings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose columns to generate embeddings.\n",
    "listings = listings[['id','listing_url','name','description','neighborhood_overview','picture_url', \n",
    "'property_type','room_type','accommodates','bathrooms','bathrooms_text',                               \n",
    "'bedrooms','beds','amenities','price','minimum_nights','maximum_nights','review_scores_rating',                         \n",
    "'review_scores_accuracy','review_scores_cleanliness','review_scores_checkin',\n",
    "'review_scores_communication','review_scores_location']]\n",
    "\n",
    "listings.fillna('0', inplace=True)\n",
    "\n",
    "listings.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punc(sample_str):\n",
    "    # Create translation table in which special charcters\n",
    "    # are mapped to empty string\n",
    "    translation_table = str.maketrans('', '', string.punctuation)\n",
    "    # Remove special characters from the string using translation table\n",
    "    sample_str = sample_str.translate(translation_table)\n",
    "    return sample_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-8769852d1023>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  listings['review_scores_rating'][ind] = (float(listings['review_scores_rating'][ind]) + float(listings['review_scores_accuracy'][ind]) + float(listings['review_scores_cleanliness'][ind]) + float(listings['review_scores_checkin'][ind]) + float(listings['review_scores_communication'][ind]) + float(listings['review_scores_location'][ind]))\n",
      "<ipython-input-11-8769852d1023>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  listings['review_scores_rating'][ind] = (listings['review_scores_rating'][ind])/6\n",
      "<ipython-input-11-8769852d1023>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  listings['words_features'][ind] = 'amenities:'+listings['words_features'][ind] +'description:'+  listings['description'][ind] +'neighborhood_overview:'+  listings['neighborhood_overview'][ind]+'property_type:'+  listings['property_type'][ind]+'room_type:'+  listings['room_type'][ind]+'accommodates:'+  str(listings['accommodates'][ind])+'bedrooms:'+  str(listings['bedrooms'][ind])+'beds:'+  str(listings['beds'][ind])+'price range:'+  listings['price'][ind]\n"
     ]
    }
   ],
   "source": [
    "listings['words_features'] = listings['amenities'].apply(remove_punc)\n",
    "\n",
    "for ind in listings.index:\n",
    "     listings['review_scores_rating'][ind] = (float(listings['review_scores_rating'][ind]) + float(listings['review_scores_accuracy'][ind]) + float(listings['review_scores_cleanliness'][ind]) + float(listings['review_scores_checkin'][ind]) + float(listings['review_scores_communication'][ind]) + float(listings['review_scores_location'][ind]))\n",
    "     listings['review_scores_rating'][ind] = (listings['review_scores_rating'][ind])/6\n",
    "     listings['words_features'][ind] = 'amenities:'+listings['words_features'][ind] +'description:'+  listings['description'][ind] +'neighborhood_overview:'+  listings['neighborhood_overview'][ind]+'property_type:'+  listings['property_type'][ind]+'room_type:'+  listings['room_type'][ind]+'accommodates:'+  str(listings['accommodates'][ind])+'bedrooms:'+  str(listings['bedrooms'][ind])+'beds:'+  str(listings['beds'][ind])+'price range:'+  listings['price'][ind]\n",
    "listings = listings.rename(columns={\"review_scores_rating\": \"overall_rating\"})\n",
    "listings[\"overall_rating\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47441616654396057 | https://www.airbnb.com/rooms/25991654\n",
      "0.4695029556751251 | https://www.airbnb.com/rooms/49927889\n",
      "0.4445381164550781 | https://www.airbnb.com/rooms/40247038\n",
      "0.4402620494365692 | https://www.airbnb.com/rooms/16685383\n",
      "0.4321826100349426 | https://www.airbnb.com/rooms/8641456\n",
      "0.43041324615478516 | https://www.airbnb.com/rooms/51961840\n",
      "0.4150310456752777 | https://www.airbnb.com/rooms/39642322\n",
      "0.41212931275367737 | https://www.airbnb.com/rooms/32729549\n",
      "0.4020345211029053 | https://www.airbnb.com/rooms/28854693\n",
      "0.3988373875617981 | https://www.airbnb.com/rooms/6356312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-75f26069de46>:5: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  sims = text_corpus_model.docvecs.most_similar(positive = [test_doc_vector])\n"
     ]
    }
   ],
   "source": [
    "text_corpus_model = create_embeddings(listings['words_features'].values,'list')\n",
    "\n",
    "new_doc = gensim.parsing.preprocessing.preprocess_string(\"private room dishwasher\")\n",
    "test_doc_vector = text_corpus_model.infer_vector(new_doc)\n",
    "sims = text_corpus_model.docvecs.most_similar(positive = [test_doc_vector])\n",
    "for s in sims:\n",
    "    print(f\"{(s[1])} | {listings['listing_url'].iloc[s[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering\n",
    "- https://github.com/SarangDeshmukh7/Recommendation-Engine/blob/master/Content_Based_Filtering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = reviews[\"reviewer_id\"].unique().tolist()\n",
    "random.shuffle(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_listing = pd.merge(listings,reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews_listing['listing_id']= reviews_listing['listing_id'].astype(str)\n",
    "\n",
    "# extract 90% of user ID's\n",
    "users_train = [users[i] for i in range(round(0.9*len(users)))]\n",
    "#split data into train and validation set\n",
    "train_df = reviews_listing[reviews_listing['reviewer_id'].isin(users_train)]\n",
    "validation_df = reviews_listing[~reviews_listing['reviewer_id'].isin(users_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216855/216855 [01:54<00:00, 1895.44it/s]\n"
     ]
    }
   ],
   "source": [
    "#list to capture watch history of the users\n",
    "watch_train = []\n",
    "\n",
    "# populate the list with the movie ID\n",
    "for i in tqdm(users_train):\n",
    "    temp = train_df[train_df[\"reviewer_id\"] == i][\"listing_id\"].tolist()\n",
    "    watch_train.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-253729522d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwatch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model.train(watch_train, total_examples = model.corpus_count, \n\u001b[0m\u001b[1;32m     10\u001b[0m             epochs=10, report_delay=1)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_training_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_check_training_sanity\u001b[0;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# should be set by `build_vocab`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must first build vocabulary before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must initialize vectors before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "# train word2vec model\n",
    "model = Word2Vec(window = 10, sg = 1, hs = 0,\n",
    "                 negative = 10, \n",
    "                 alpha=0.03, min_alpha=0.0007,\n",
    "                 seed = 14)\n",
    "\n",
    "model.build_vocab(watch_train, progress_per=200)\n",
    "\n",
    "model.train(watch_train, total_examples = model.corpus_count, \n",
    "            epochs=10, report_delay=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.train(watch_train, total_examples = model.corpus_count, \n",
    "            epochs=10, report_delay=1)\n",
    "model.save(model_root+'ContentBasedFilter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-b3d13b8f8448>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  watch.drop_duplicates(inplace=True, subset='listing_id', keep=\"last\")\n"
     ]
    }
   ],
   "source": [
    "watch = train_df[[\"listing_id\",\"listing_url\",\"name\"]]\n",
    "\n",
    "# remove duplicates\n",
    "watch.drop_duplicates(inplace=True, subset='listing_id', keep=\"last\")\n",
    "\n",
    "# create movie id and tittle dictionary\n",
    "watch_dict = watch.groupby('listing_id')['listing_id'].apply(list).to_dict()\n",
    "\n",
    "def similar_watch(v, n = 5):\n",
    "\n",
    "    # extract most similar movies for the input vector\n",
    "    ms = model.wv.similar_by_vector(v, topn= n+1)[1:]\n",
    "    # extract name and similarity score of the similar movies\n",
    "    new_ms = []\n",
    "    for j in ms:\n",
    "        pair = (watch_dict[j[0]][0], j[1])\n",
    "        new_ms.append(pair)\n",
    "        \n",
    "    return new_ms        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quiet Garden View Room & Super Fast WiFi']\n"
     ]
    }
   ],
   "source": [
    "print(watch_dict['2818'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1383369', 0.9963660836219788),\n",
       " ('505650', 0.9962319135665894),\n",
       " ('18882385', 0.9962259531021118),\n",
       " ('28170875', 0.9961230158805847),\n",
       " ('23332938', 0.9960837364196777)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_watch('2818',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Refer notebook ColaborativeFiltering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "Requirement already satisfied: pyspark in /opt/anaconda3/lib/python3.8/site-packages (3.2.0)\n",
      "Requirement already satisfied: py4j==0.10.9.2 in /opt/anaconda3/lib/python3.8/site-packages (from pyspark) (0.10.9.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -atplotlib (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "+--------------------+--------------------+--------------+------------+--------------------+--------------------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+----------------+------------------+--------------------+-------------------------+------------------+--------------------+----------------------+-------------+----------------------+----------------------------+--------+---------+-------------+---------+------------+---------+--------------+--------+----+---------+-----+--------------+--------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------+----------------+---------------+---------------+---------------+----------------+---------------------+-----------------+---------------------+----------------------+------------+-----------+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+-------+----------------+------------------------------+-------------------------------------------+--------------------------------------------+-------------------------------------------+-----------------+\n",
      "|                  id|         listing_url|     scrape_id|last_scraped|                name|         description|neighborhood_overview|         picture_url|             host_id|            host_url|           host_name|          host_since|       host_location|          host_about|  host_response_time|  host_response_rate|host_acceptance_rate|host_is_superhost|  host_thumbnail_url|host_picture_url|host_neighbourhood| host_listings_count|host_total_listings_count|host_verifications|host_has_profile_pic|host_identity_verified|neighbourhood|neighbourhood_cleansed|neighbourhood_group_cleansed|latitude|longitude|property_type|room_type|accommodates|bathrooms|bathrooms_text|bedrooms|beds|amenities|price|minimum_nights|maximum_nights|minimum_minimum_nights|maximum_minimum_nights|minimum_maximum_nights|maximum_maximum_nights|minimum_nights_avg_ntm|maximum_nights_avg_ntm|calendar_updated|has_availability|availability_30|availability_60|availability_90|availability_365|calendar_last_scraped|number_of_reviews|number_of_reviews_ltm|number_of_reviews_l30d|first_review|last_review|review_scores_rating|review_scores_accuracy|review_scores_cleanliness|review_scores_checkin|review_scores_communication|review_scores_location|review_scores_value|license|instant_bookable|calculated_host_listings_count|calculated_host_listings_count_entire_homes|calculated_host_listings_count_private_rooms|calculated_host_listings_count_shared_rooms|reviews_per_month|\n",
      "+--------------------+--------------------+--------------+------------+--------------------+--------------------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+----------------+------------------+--------------------+-------------------------+------------------+--------------------+----------------------+-------------+----------------------+----------------------------+--------+---------+-------------+---------+------------+---------+--------------+--------+----+---------+-----+--------------+--------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------+----------------+---------------+---------------+---------------+----------------+---------------------+-----------------+---------------------+----------------------+------------+-----------+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+-------+----------------+------------------------------+-------------------------------------------+--------------------------------------------+-------------------------------------------+-----------------+\n",
      "|                2818|https://www.airbn...|20211104024252|  2021-11-04|Quiet Garden View...|\"Quiet Garden Vie...|  down quilts and ...| connection for m...|\"Indische Buurt (...| in the Dutch pro...| there were aroun...|357 inhabitants. ...| on the east side...| on the north sid...| and a high perce...| but higher in th...|https://a0.muscac...|             3159|https://www.airbn...|          Daniel|        2008-09-24|Amsterdam, Noord-...|     Upon arriving in ...|              null|                null|                  null|         null|                  null|                        null|    null|     null|         null|     null|        null|     null|          null|    null|null|     null| null|          null|          null|                  null|                  null|                  null|                  null|                  null|                  null|            null|            null|           null|           null|           null|            null|                 null|             null|                 null|                  null|        null|       null|                null|                  null|                     null|                 null|                       null|                  null|               null|   null|            null|                          null|                                       null|                                        null|                                       null|             null|\n",
      "|How can I experie...| eat and sleep li...|          null|        null|                null|                null|                 null|                null|                null|                null|                null|                null|                null|                null|                null|                null|                null|             null|                null|            null|              null|                null|                     null|              null|                null|                  null|         null|                  null|                        null|    null|     null|         null|     null|        null|     null|          null|    null|null|     null| null|          null|          null|                  null|                  null|                  null|                  null|                  null|                  null|            null|            null|           null|           null|           null|            null|                 null|             null|                 null|                  null|        null|       null|                null|                  null|                     null|                 null|                       null|                  null|               null|   null|            null|                          null|                                       null|                                        null|                                       null|             null|\n",
      "+--------------------+--------------------+--------------+------------+--------------------+--------------------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+----------------+------------------+--------------------+-------------------------+------------------+--------------------+----------------------+-------------+----------------------+----------------------------+--------+---------+-------------+---------+------------+---------+--------------+--------+----+---------+-----+--------------+--------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------+----------------+---------------+---------------+---------------+----------------+---------------------+-----------------+---------------------+----------------------+------------+-----------+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+-------+----------------+------------------------------+-------------------------------------------+--------------------------------------------+-------------------------------------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+\n",
      "|                  id|\n",
      "+--------------------+\n",
      "|We are Fleur & Ev...|\n",
      "|\",within an hour,...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+----+----------+-----------+-------------+--------------------+------+\n",
      "|listing_id|  id|      date|reviewer_id|reviewer_name|            comments|rating|\n",
      "+----------+----+----------+-----------+-------------+--------------------+------+\n",
      "|      2818|1191|2009-03-30|      10952|          Lam|Daniel is really ...|     3|\n",
      "|      2818|1771|2009-04-24|      12798|        Alice|Daniel is the mos...|     4|\n",
      "+----------+----+----------+-----------+-------------+--------------------+------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+----+----------+-----------+-------------+--------------------+------+\n",
      "|listing_id|  id|      date|reviewer_id|reviewer_name|            comments|rating|\n",
      "+----------+----+----------+-----------+-------------+--------------------+------+\n",
      "|      2818|1191|2009-03-30|      10952|          Lam|Daniel is really ...|     3|\n",
      "|      2818|1771|2009-04-24|      12798|        Alice|Daniel is the mos...|     4|\n",
      "+----------+----+----------+-----------+-------------+--------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspark\n",
    "\n",
    "# importing all the libraries we’ll require to build the book recommender\n",
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions  import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.recommendation import ALS,ALSModel\n",
    "\n",
    "# define the configurations for this Spark program\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"airbnb\")\n",
    "conf.set(\"spark.executor.memory\", \"6G\")\n",
    "conf.set(\"spark.driver.memory\", \"2G\")\n",
    "conf.set(\"spark.executor.cores\", \"4\")\n",
    "conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "conf.set(\"spark.default.parallelism\", \"4\")\n",
    "\n",
    "# create a Spark Session instead of a Spark Context\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf = conf) \\\n",
    "  .appName(\"spark session example\") \\\n",
    "  .getOrCreate()\n",
    "\n",
    "listings_df = spark.read.option(\"delimiter\", \",\").option(\"header\", \"true\").csv(raw+'listings.csv.gz')\n",
    "listings_df.show(2)\n",
    "\n",
    "listings_df.select('id').distinct().show(2)\n",
    "\n",
    "user_ratings_df = spark.read.option(\"delimiter\", \",\").option(\"header\", \"true\").csv(processed+'ratings_filter.csv')\n",
    "# Columns User-ID, ISBN and Book-Rating were in string format, which we convert to int\n",
    "ratings_df = user_ratings_df.withColumn(\"reviewer_id\",\n",
    "                                        user_ratings_df['reviewer_id'].\\\n",
    "                                        cast(IntegerType())).\\\n",
    "\t\t\t\t\t\t\t\t\t\twithColumn(\"listing_id\", user_ratings_df['listing_id'].\\\n",
    "           \t\t\t\t\t\t\t\tcast(IntegerType())).\\\n",
    "    \t\t\t\t\t\t\t\t\twithColumn(\"rating\",\\\n",
    "                                        user_ratings_df['rating'].\\\n",
    "                                  \t\tcast(IntegerType())).\\\n",
    "        \t\t\t\t\t\t\t\tna.drop()\n",
    "ratings_df.show(2)\n",
    "\n",
    "# define parameters\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"reviewer_id\", itemCol=\"listing_id\", ratingCol=\"rating\",coldStartStrategy=\"drop\")\n",
    "#fit the model to the ratings\n",
    "model = als.fit(ratings_df)\n",
    "\n",
    "model.save(model_root+\"als_model\")\n",
    "\n",
    "user_ratings_df = spark.read.option(\"delimiter\", \",\").option(\"header\", \"true\").csv(processed+'ratings_filter.csv')\n",
    "# Columns User-ID, ISBN and Book-Rating were in string format, which we convert to int\n",
    "ratings_df = user_ratings_df.withColumn(\"reviewer_id\",\n",
    "                                        user_ratings_df['reviewer_id'].\\\n",
    "                                        cast(IntegerType())).\\\n",
    "\t\t\t\t\t\t\t\t\t\twithColumn(\"listing_id\", user_ratings_df['listing_id'].\\\n",
    "           \t\t\t\t\t\t\t\tcast(IntegerType())).\\\n",
    "    \t\t\t\t\t\t\t\t\twithColumn(\"rating\",\\\n",
    "                                        user_ratings_df['rating'].\\\n",
    "                                  \t\tcast(IntegerType())).\\\n",
    "        \t\t\t\t\t\t\t\tna.drop()\n",
    "ratings_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help link Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Text, Dict, List\n",
    "import torch\n",
    "from bert_serving.client import BertClient\n",
    "from rasa_sdk import Action, Tracker\n",
    "from rasa_sdk.executor import CollectingDispatcher\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# sentence embedding selection\n",
    "sentence_transformer_select=True\n",
    "pretrained_model='stsb-roberta-large' # Refer: https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/nli-models.md\n",
    "score_threshold = 0.70  # This confidence scores can be adjusted based on your need!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard question size 86\n",
      "Start to calculate encoder....\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def encode_standard_question(sentence_transformer_select=True, pretrained_model='bert-base-nli-mean-tokens'):\n",
    "    \"\"\"\n",
    "    This will encode all the questions available in question database into sentence embedding. The result will be stored into numpy array for comparision purpose.\n",
    "    \"\"\"\n",
    "    if sentence_transformer_select:\n",
    "        bc = SentenceTransformer(pretrained_model)\n",
    "    else:\n",
    "        bc = BertClient(check_version=False)\n",
    "    data = json.load(open(raw+\"/faq.json\", \"rt\", encoding=\"utf-8\"))\n",
    "    standard_questions = [each['q'].replace('-',' ') for each in data]\n",
    "    print(\"Standard question size\", len(standard_questions))\n",
    "    print(\"Start to calculate encoder....\")\n",
    "    if sentence_transformer_select:\n",
    "        standard_questions_encoder = torch.tensor(bc.encode(standard_questions)).numpy()\n",
    "    else:\n",
    "        standard_questions_encoder = bc.encode(standard_questions)\n",
    "    np.save(root+\"embeddings/questions_embedding\", standard_questions_encoder)\n",
    "    standard_questions_encoder_len = np.sqrt(np.sum(standard_questions_encoder * standard_questions_encoder, axis=1))\n",
    "    np.save(root+\"embeddings/questions_embedding_len\", standard_questions_encoder_len)\n",
    "\n",
    "\n",
    "encode_standard_question(sentence_transformer_select,pretrained_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
